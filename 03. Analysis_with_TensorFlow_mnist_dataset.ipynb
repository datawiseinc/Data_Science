{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of MNIST dataset with tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the relevan libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the sizes of the test data\n",
    "test_size = mnist_info.splits['test'].num_examples\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the size of the training data\n",
    "train_size = mnist_info.splits['train'].num_examples\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the size of the validation data\n",
    "validation_size = tf.cast(0.1 * train_size, tf.int64)\n",
    "validation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the train data\n",
    "train_validation_data = mnist_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the test data\n",
    "test_mnist_data = mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image matrices take integer values ranging from 0 to 255\n",
    "# write a function to scale it so that they range from 0 to 1\n",
    "\n",
    "def scale_image(image, label):\n",
    "    \n",
    "    #convert integer values to float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    #scale the images\n",
    "    image = image / 255\n",
    "    \n",
    "    #return the values\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the train data\n",
    "scaled_train_validation_data = train_validation_data.map(scale_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the test data\n",
    "scaled_test_data = test_mnist_data.map(scale_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the BUFFER SIZE for shuffling large data sets\n",
    "buffer_size = 10000\n",
    "\n",
    "#shuffle the train data (no need to shuffle test_data)\n",
    "shuffled_scaled_train_validation_data = scaled_train_validation_data.shuffle(buffer_size = buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the validation data\n",
    "shuffled_scaled_validation_data = shuffled_scaled_train_validation_data.take(validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the train data\n",
    "shuffled_scaled_train_data = shuffled_scaled_train_validation_data.skip(validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the batch size for SGD (stochastic gradient descent)\n",
    "batch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch the training data\n",
    "train_data = shuffled_scaled_train_data.batch(batch_size = batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch the validation data\n",
    "validation_data = shuffled_scaled_validation_data.batch(validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch the test data\n",
    "test_data = scaled_test_data.batch(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate validation inputs and outputs\n",
    "validation_inputs, validation_outputs = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the input size (each image is 28x28 pixels)\n",
    "input_size = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the number of outputs (to one-hot-code a digit we need ten outputs)\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hidden layer size\n",
    "#traditionally all hidden layers have the same size\n",
    "hidden_layer_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model as sequential layers of inputs, hidden layers and outputs\n",
    "model = tf.keras.Sequential([\n",
    "                               #flatten the (28X28X1) tensor of rank 3 to (784,) or feed it to CNN \n",
    "                               tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                                \n",
    "                               #stack the hidden layers and apply activation functions \n",
    "                               tf.keras.layers.Dense(hidden_layer_size, activation='relu' ),\n",
    "    \n",
    "                               #stack another hidden layer and apply the activation function\n",
    "                               tf.keras.layers.Dense(hidden_layer_size, activation='relu' ),\n",
    "                    \n",
    "                               #apply as many hidden layer as needed       \n",
    "                                \n",
    "                               #stack final layer and apply the softmax activation function to return 1s and 0s\n",
    "                               tf.keras.layers.Dense(output_size, activation='softmax' )    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the optimizer and the loss function\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly pick the number of epochs\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the data\n",
    "model.fit(train_data, epochs=num_epochs, validation_data= (validation_inputs, validation_outputs ), \n",
    "          verbose=2, validation_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Test loss is {:.2f} and test accuracy is {:.2f}%'.format(test_loss, test_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This model is able to predict 98% of the hand written digits correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
